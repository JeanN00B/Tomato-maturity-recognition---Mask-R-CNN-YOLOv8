{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzJWlLqCVRcG",
        "outputId": "ec8076f9-79df-4cc6-c113-6014db2b82e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1WByPFNVdFO",
        "outputId": "f81591a9-fcb9-4f3a-f8a1-b2f72ebdb5b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Tomato-Dataset\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/Tomato-Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ALuhQ_kjV6oo",
        "outputId": "47888771-537d-49f0-932a-b2df33b04355"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openmim\n",
            "  Downloading openmim-0.3.6-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.3/51.3 KB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorama\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from openmim) (1.3.5)\n",
            "Collecting model-index\n",
            "  Downloading model_index-0.1.11-py3-none-any.whl (34 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from openmim) (2.25.1)\n",
            "Collecting rich\n",
            "  Downloading rich-13.3.1-py3-none-any.whl (239 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.0/239.0 KB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tabulate in /usr/local/lib/python3.8/dist-packages (from openmim) (0.8.10)\n",
            "Requirement already satisfied: pip>=19.3 in /usr/local/lib/python3.8/dist-packages (from openmim) (22.0.4)\n",
            "Requirement already satisfied: Click in /usr/local/lib/python3.8/dist-packages (from openmim) (7.1.2)\n",
            "Collecting ordered-set\n",
            "  Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from model-index->openmim) (6.0)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.8/dist-packages (from model-index->openmim) (3.4.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->openmim) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->openmim) (2022.7.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from pandas->openmim) (1.21.6)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->openmim) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->openmim) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->openmim) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->openmim) (2022.12.7)\n",
            "Collecting pygments<3.0.0,>=2.14.0\n",
            "  Downloading Pygments-2.14.0-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions<5.0,>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from rich->openmim) (4.5.0)\n",
            "Collecting markdown-it-py<3.0.0,>=2.1.0\n",
            "  Downloading markdown_it_py-2.1.0-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 KB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mdurl~=0.1\n",
            "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->openmim) (1.15.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown->model-index->openmim) (6.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown->model-index->openmim) (3.13.0)\n",
            "Installing collected packages: pygments, ordered-set, mdurl, colorama, markdown-it-py, rich, model-index, openmim\n",
            "  Attempting uninstall: pygments\n",
            "    Found existing installation: Pygments 2.6.1\n",
            "    Uninstalling Pygments-2.6.1:\n",
            "      Successfully uninstalled Pygments-2.6.1\n",
            "Successfully installed colorama-0.4.6 markdown-it-py-2.1.0 mdurl-0.1.2 model-index-0.1.11 openmim-0.3.6 ordered-set-4.1.0 pygments-2.14.0 rich-13.3.1\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pygments"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://download.openmmlab.com/mmcv/dist/cu116/torch1.13.0/index.html\n",
            "Collecting mmcv-full\n",
            "  Downloading https://download.openmmlab.com/mmcv/dist/cu116/torch1.13.0/mmcv_full-1.7.1-cp38-cp38-manylinux1_x86_64.whl (46.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.1/46.1 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.8/dist-packages (from mmcv-full) (4.6.0.66)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from mmcv-full) (1.21.6)\n",
            "Collecting addict\n",
            "  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Collecting yapf\n",
            "  Downloading yapf-0.32.0-py2.py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.2/190.2 KB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from mmcv-full) (7.1.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from mmcv-full) (6.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from mmcv-full) (23.0)\n",
            "Installing collected packages: yapf, addict, mmcv-full\n",
            "Successfully installed addict-2.4.0 mmcv-full-1.7.1 yapf-0.32.0\n"
          ]
        }
      ],
      "source": [
        "!pip3 install jedi>=0.10\n",
        "!pip3 install openmim\n",
        "!mim install mmcv-full\n",
        "!pip install light-the-torch\n",
        "!ltt install torch torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HzQgtAW_V8bn",
        "outputId": "dd074b4e-31c5-49d9-bbf1-df8852842f93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Tomato-Dataset/mmdetection\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Obtaining file:///content/drive/MyDrive/Tomato-Dataset/mmdetection\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from mmdet==2.28.1) (3.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from mmdet==2.28.1) (1.21.6)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.8/dist-packages (from mmdet==2.28.1) (2.0.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from mmdet==2.28.1) (1.7.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from mmdet==2.28.1) (1.15.0)\n",
            "Collecting terminaltables\n",
            "  Downloading terminaltables-3.1.10-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->mmdet==2.28.1) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->mmdet==2.28.1) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->mmdet==2.28.1) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->mmdet==2.28.1) (3.0.9)\n",
            "Installing collected packages: terminaltables, mmdet\n",
            "  Running setup.py develop for mmdet\n",
            "Successfully installed mmdet-2.28.1 terminaltables-3.1.10\n"
          ]
        }
      ],
      "source": [
        "#!git clone https://github.com/open-mmlab/mmdetection.git\n",
        "%cd mmdetection\n",
        "!pip install -e ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSrljXUKXpRs",
        "outputId": "e5eeeffb-8ceb-4e6c-fad6-2d820b6fd6b7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n",
            "/usr/local/lib/python3.8/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.28.1\n"
          ]
        }
      ],
      "source": [
        "import mmdet\n",
        "import mmcv\n",
        "import os\n",
        "\n",
        "from mmdet.datasets import build_dataset\n",
        "from mmdet.models import build_detector\n",
        "from mmdet.apis import train_detector\n",
        "from mmdet.apis import set_random_seed\n",
        "from mmcv import Config\n",
        "\n",
        "print(mmdet.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xaXumy7t8A_h",
        "outputId": "948d2b7f-e5d1-4df8-d580-c7c8c24f196e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Config:\n",
            "model = dict(\n",
            "    type='MaskRCNN',\n",
            "    backbone=dict(\n",
            "        type='ResNet',\n",
            "        depth=101,\n",
            "        num_stages=4,\n",
            "        out_indices=(0, 1, 2, 3),\n",
            "        frozen_stages=1,\n",
            "        norm_cfg=dict(type='BN', requires_grad=False),\n",
            "        norm_eval=True,\n",
            "        style='caffe',\n",
            "        init_cfg=dict(\n",
            "            type='Pretrained',\n",
            "            checkpoint='open-mmlab://detectron2/resnet101_caffe')),\n",
            "    neck=dict(\n",
            "        type='FPN',\n",
            "        in_channels=[256, 512, 1024, 2048],\n",
            "        out_channels=256,\n",
            "        num_outs=5),\n",
            "    rpn_head=dict(\n",
            "        type='RPNHead',\n",
            "        in_channels=256,\n",
            "        feat_channels=256,\n",
            "        anchor_generator=dict(\n",
            "            type='AnchorGenerator',\n",
            "            scales=[8],\n",
            "            ratios=[0.5, 1.0, 2.0],\n",
            "            strides=[4, 8, 16, 32, 64]),\n",
            "        bbox_coder=dict(\n",
            "            type='DeltaXYWHBBoxCoder',\n",
            "            target_means=[0.0, 0.0, 0.0, 0.0],\n",
            "            target_stds=[1.0, 1.0, 1.0, 1.0]),\n",
            "        loss_cls=dict(\n",
            "            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n",
            "        loss_bbox=dict(type='L1Loss', loss_weight=1.0)),\n",
            "    roi_head=dict(\n",
            "        type='StandardRoIHead',\n",
            "        bbox_roi_extractor=dict(\n",
            "            type='SingleRoIExtractor',\n",
            "            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=0),\n",
            "            out_channels=256,\n",
            "            featmap_strides=[4, 8, 16, 32]),\n",
            "        bbox_head=dict(\n",
            "            type='Shared2FCBBoxHead',\n",
            "            in_channels=256,\n",
            "            fc_out_channels=1024,\n",
            "            roi_feat_size=7,\n",
            "            num_classes=3,\n",
            "            bbox_coder=dict(\n",
            "                type='DeltaXYWHBBoxCoder',\n",
            "                target_means=[0.0, 0.0, 0.0, 0.0],\n",
            "                target_stds=[0.1, 0.1, 0.2, 0.2]),\n",
            "            reg_class_agnostic=False,\n",
            "            loss_cls=dict(\n",
            "                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),\n",
            "            loss_bbox=dict(type='L1Loss', loss_weight=1.0)),\n",
            "        mask_roi_extractor=dict(\n",
            "            type='SingleRoIExtractor',\n",
            "            roi_layer=dict(type='RoIAlign', output_size=14, sampling_ratio=0),\n",
            "            out_channels=256,\n",
            "            featmap_strides=[4, 8, 16, 32]),\n",
            "        mask_head=dict(\n",
            "            type='FCNMaskHead',\n",
            "            num_convs=4,\n",
            "            in_channels=256,\n",
            "            conv_out_channels=256,\n",
            "            num_classes=3,\n",
            "            loss_mask=dict(\n",
            "                type='CrossEntropyLoss', use_mask=True, loss_weight=1.0))),\n",
            "    train_cfg=dict(\n",
            "        rpn=dict(\n",
            "            assigner=dict(\n",
            "                type='MaxIoUAssigner',\n",
            "                pos_iou_thr=0.7,\n",
            "                neg_iou_thr=0.3,\n",
            "                min_pos_iou=0.3,\n",
            "                match_low_quality=True,\n",
            "                ignore_iof_thr=-1),\n",
            "            sampler=dict(\n",
            "                type='RandomSampler',\n",
            "                num=256,\n",
            "                pos_fraction=0.5,\n",
            "                neg_pos_ub=-1,\n",
            "                add_gt_as_proposals=False),\n",
            "            allowed_border=-1,\n",
            "            pos_weight=-1,\n",
            "            debug=False),\n",
            "        rpn_proposal=dict(\n",
            "            nms_pre=2000,\n",
            "            max_per_img=1000,\n",
            "            nms=dict(type='nms', iou_threshold=0.7),\n",
            "            min_bbox_size=0),\n",
            "        rcnn=dict(\n",
            "            assigner=dict(\n",
            "                type='MaxIoUAssigner',\n",
            "                pos_iou_thr=0.5,\n",
            "                neg_iou_thr=0.5,\n",
            "                min_pos_iou=0.5,\n",
            "                match_low_quality=True,\n",
            "                ignore_iof_thr=-1),\n",
            "            sampler=dict(\n",
            "                type='RandomSampler',\n",
            "                num=512,\n",
            "                pos_fraction=0.25,\n",
            "                neg_pos_ub=-1,\n",
            "                add_gt_as_proposals=True),\n",
            "            mask_size=28,\n",
            "            pos_weight=-1,\n",
            "            debug=False)),\n",
            "    test_cfg=dict(\n",
            "        rpn=dict(\n",
            "            nms_pre=1000,\n",
            "            max_per_img=1000,\n",
            "            nms=dict(type='nms', iou_threshold=0.7),\n",
            "            min_bbox_size=0),\n",
            "        rcnn=dict(\n",
            "            score_thr=0.05,\n",
            "            nms=dict(type='nms', iou_threshold=0.5),\n",
            "            max_per_img=100,\n",
            "            mask_thr_binary=0.5)))\n",
            "dataset_type = 'COCODataset'\n",
            "data_root = 'data/coco/'\n",
            "img_norm_cfg = dict(\n",
            "    mean=[103.53, 116.28, 123.675], std=[1.0, 1.0, 1.0], to_rgb=False)\n",
            "train_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
            "    dict(type='Resize', img_scale=(1333, 800), keep_ratio=True),\n",
            "    dict(type='RandomFlip', flip_ratio=0.5),\n",
            "    dict(\n",
            "        type='Normalize',\n",
            "        mean=[103.53, 116.28, 123.675],\n",
            "        std=[1.0, 1.0, 1.0],\n",
            "        to_rgb=False),\n",
            "    dict(type='Pad', size_divisor=32),\n",
            "    dict(type='DefaultFormatBundle'),\n",
            "    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels', 'gt_masks'])\n",
            "]\n",
            "test_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(\n",
            "        type='MultiScaleFlipAug',\n",
            "        img_scale=(1333, 800),\n",
            "        flip=False,\n",
            "        transforms=[\n",
            "            dict(type='Resize', keep_ratio=True),\n",
            "            dict(type='RandomFlip'),\n",
            "            dict(\n",
            "                type='Normalize',\n",
            "                mean=[103.53, 116.28, 123.675],\n",
            "                std=[1.0, 1.0, 1.0],\n",
            "                to_rgb=False),\n",
            "            dict(type='Pad', size_divisor=32),\n",
            "            dict(type='ImageToTensor', keys=['img']),\n",
            "            dict(type='Collect', keys=['img'])\n",
            "        ])\n",
            "]\n",
            "data = dict(\n",
            "    samples_per_gpu=2,\n",
            "    workers_per_gpu=2,\n",
            "    train=dict(\n",
            "        type='CocoDataset',\n",
            "        ann_file=\n",
            "        '/content/drive/MyDrive/Tomato-Dataset/Big_tomatoes_dataset-2/annotations/train.json',\n",
            "        img_prefix=\n",
            "        '/content/drive/MyDrive/Tomato-Dataset/Big_tomatoes_dataset-2/train/',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
            "            dict(type='Resize', img_scale=(1333, 800), keep_ratio=True),\n",
            "            dict(type='RandomFlip', flip_ratio=0.5),\n",
            "            dict(\n",
            "                type='Normalize',\n",
            "                mean=[103.53, 116.28, 123.675],\n",
            "                std=[1.0, 1.0, 1.0],\n",
            "                to_rgb=False),\n",
            "            dict(type='Pad', size_divisor=32),\n",
            "            dict(type='DefaultFormatBundle'),\n",
            "            dict(\n",
            "                type='Collect',\n",
            "                keys=['img', 'gt_bboxes', 'gt_labels', 'gt_masks'])\n",
            "        ],\n",
            "        classes=('b_fully_ripened', 'b_green', 'b_half_ripened')),\n",
            "    val=dict(\n",
            "        type='CocoDataset',\n",
            "        ann_file=\n",
            "        '/content/drive/MyDrive/Tomato-Dataset/Big_tomatoes_dataset-2/annotations/valid.json',\n",
            "        img_prefix=\n",
            "        '/content/drive/MyDrive/Tomato-Dataset/Big_tomatoes_dataset-2/valid/',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(\n",
            "                type='MultiScaleFlipAug',\n",
            "                img_scale=(1333, 800),\n",
            "                flip=False,\n",
            "                transforms=[\n",
            "                    dict(type='Resize', keep_ratio=True),\n",
            "                    dict(type='RandomFlip'),\n",
            "                    dict(\n",
            "                        type='Normalize',\n",
            "                        mean=[103.53, 116.28, 123.675],\n",
            "                        std=[1.0, 1.0, 1.0],\n",
            "                        to_rgb=False),\n",
            "                    dict(type='Pad', size_divisor=32),\n",
            "                    dict(type='ImageToTensor', keys=['img']),\n",
            "                    dict(type='Collect', keys=['img'])\n",
            "                ])\n",
            "        ],\n",
            "        classes=('b_fully_ripened', 'b_green', 'b_half_ripened')),\n",
            "    test=dict(\n",
            "        type='CocoDataset',\n",
            "        ann_file=\n",
            "        '/content/drive/MyDrive/Tomato-Dataset/Big_tomatoes_dataset-2/annotations/test.json',\n",
            "        img_prefix=\n",
            "        '/content/drive/MyDrive/Tomato-Dataset/Big_tomatoes_dataset-2/test/',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(\n",
            "                type='MultiScaleFlipAug',\n",
            "                img_scale=(1333, 800),\n",
            "                flip=False,\n",
            "                transforms=[\n",
            "                    dict(type='Resize', keep_ratio=True),\n",
            "                    dict(type='RandomFlip'),\n",
            "                    dict(\n",
            "                        type='Normalize',\n",
            "                        mean=[103.53, 116.28, 123.675],\n",
            "                        std=[1.0, 1.0, 1.0],\n",
            "                        to_rgb=False),\n",
            "                    dict(type='Pad', size_divisor=32),\n",
            "                    dict(type='ImageToTensor', keys=['img']),\n",
            "                    dict(type='Collect', keys=['img'])\n",
            "                ])\n",
            "        ],\n",
            "        classes=('b_fully_ripened', 'b_green', 'b_half_ripened')))\n",
            "evaluation = dict(metric=['bbox', 'segm'])\n",
            "optimizer = dict(type='SGD', lr=0.0025, momentum=0.9, weight_decay=0.0001)\n",
            "optimizer_config = dict(grad_clip=None)\n",
            "lr_config = dict(\n",
            "    policy='step',\n",
            "    warmup=None,\n",
            "    warmup_iters=500,\n",
            "    warmup_ratio=0.001,\n",
            "    step=[8, 11])\n",
            "runner = dict(type='EpochBasedRunner', max_epochs=12)\n",
            "checkpoint_config = dict(interval=1)\n",
            "log_config = dict(\n",
            "    interval=10,\n",
            "    hooks=[dict(type='TextLoggerHook'),\n",
            "           dict(type='TensorboardLoggerHook')])\n",
            "custom_hooks = [dict(type='NumClassCheckHook')]\n",
            "dist_params = dict(backend='nccl')\n",
            "log_level = 'INFO'\n",
            "load_from = '/content/drive/MyDrive/Tomato-Dataset/mmdetection/results/Results1/latest.pth'\n",
            "resume_from = None\n",
            "workflow = [('train', 1)]\n",
            "opencv_num_threads = 0\n",
            "mp_start_method = 'fork'\n",
            "auto_scale_lr = dict(enable=False, base_batch_size=16)\n",
            "classes = ('b_fully_ripened', 'b_green', 'b_half_ripened')\n",
            "work_dir = '/content/drive/MyDrive/Tomato-Dataset/mmdetection/results'\n",
            "device = 'cpu'\n",
            "seed = 0\n",
            "gpu_ids = range(0, 1)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "cfg = Config.fromfile('/content/drive/MyDrive/Tomato-Dataset/mmdetection/configs/mask_rcnn/tomato_custom_mask_rcnn.py')\n",
        "dataset_type = 'CocoDataset'\n",
        "\n",
        "cfg.data.val.ann_file = '/content/drive/MyDrive/Tomato-Dataset/Big_tomatoes_dataset-2/annotations/valid.json'\n",
        "cfg.data.train.ann_file = '/content/drive/MyDrive/Tomato-Dataset/Big_tomatoes_dataset-2/annotations/train.json'\n",
        "cfg.data.test.ann_file = '/content/drive/MyDrive/Tomato-Dataset/Big_tomatoes_dataset-2/annotations/test.json'\n",
        "\n",
        "cfg.data.test.img_prefix = '/content/drive/MyDrive/Tomato-Dataset/Big_tomatoes_dataset-2/test/'\n",
        "cfg.data.train.img_prefix = '/content/drive/MyDrive/Tomato-Dataset/Big_tomatoes_dataset-2/train/'\n",
        "cfg.data.val.img_prefix = '/content/drive/MyDrive/Tomato-Dataset/Big_tomatoes_dataset-2/valid/'\n",
        "\n",
        "cfg.data.test.classes = ('b_fully_ripened', 'b_green', 'b_half_ripened',)\n",
        "cfg.data.train.classes = ('b_fully_ripened', 'b_green', 'b_half_ripened',)\n",
        "cfg.data.val.classes = ('b_fully_ripened', 'b_green', 'b_half_ripened',)\n",
        "\\\n",
        "\n",
        "cfg.load_from = '/content/drive/MyDrive/Tomato-Dataset/mmdetection/mask_rcnn_r101_caffe_fpn_1x_coco_20200601_095758-805e06c1.pth'\n",
        "cfg.work_dir = '/content/drive/MyDrive/Tomato-Dataset/mmdetection/results/Results'\n",
        "\n",
        "cfg.optimizer.lr = 0.02 / 8\n",
        "cfg.lr_config.warmup = None\n",
        "cfg.log_config.interval = 10\n",
        "#cfg.device='cpu'\n",
        "cfg.device='cuda'\n",
        "\n",
        "# Set seed thus the results are more reproducible\n",
        "cfg.seed = 1221410\n",
        "set_random_seed(0, deterministic=False)\n",
        "cfg.gpu_ids = range(1)\n",
        "\n",
        "# We can also use tensorboard to log the training process\n",
        "cfg.log_config.hooks = [\n",
        "    dict(type='TextLoggerHook'),\n",
        "    dict(type='TensorboardLoggerHook')]\n",
        "\n",
        "\n",
        "print(f'Config:\\n{cfg.pretty_text}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZyDRFOqFjfS",
        "outputId": "cb719b62-3009-4d69-b1d8-b056384968fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.03s)\n",
            "creating index...\n",
            "index created!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-02-21 17:28:11,541 - mmdet - INFO - Automatic scaling of learning rate (LR) has been disabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading annotations into memory...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-02-21 17:28:11,807 - mmdet - INFO - load checkpoint from local path: /content/drive/MyDrive/Tomato-Dataset/mmdetection/results/Results1/latest.pth\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done (t=0.25s)\n",
            "creating index...\n",
            "index created!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-02-21 17:28:31,995 - mmdet - INFO - Start running, host: root@b162c448722b, work_dir: /content/drive/MyDrive/Tomato-Dataset/mmdetection/results\n",
            "2023-02-21 17:28:31,997 - mmdet - INFO - Hooks will be executed in the following order:\n",
            "before_run:\n",
            "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
            "(NORMAL      ) CheckpointHook                     \n",
            "(LOW         ) EvalHook                           \n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            "(VERY_LOW    ) TensorboardLoggerHook              \n",
            " -------------------- \n",
            "before_train_epoch:\n",
            "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
            "(NORMAL      ) NumClassCheckHook                  \n",
            "(LOW         ) IterTimerHook                      \n",
            "(LOW         ) EvalHook                           \n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            "(VERY_LOW    ) TensorboardLoggerHook              \n",
            " -------------------- \n",
            "before_train_iter:\n",
            "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
            "(LOW         ) IterTimerHook                      \n",
            "(LOW         ) EvalHook                           \n",
            " -------------------- \n",
            "after_train_iter:\n",
            "(ABOVE_NORMAL) OptimizerHook                      \n",
            "(NORMAL      ) CheckpointHook                     \n",
            "(LOW         ) IterTimerHook                      \n",
            "(LOW         ) EvalHook                           \n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            "(VERY_LOW    ) TensorboardLoggerHook              \n",
            " -------------------- \n",
            "after_train_epoch:\n",
            "(NORMAL      ) CheckpointHook                     \n",
            "(LOW         ) EvalHook                           \n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            "(VERY_LOW    ) TensorboardLoggerHook              \n",
            " -------------------- \n",
            "before_val_epoch:\n",
            "(NORMAL      ) NumClassCheckHook                  \n",
            "(LOW         ) IterTimerHook                      \n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            "(VERY_LOW    ) TensorboardLoggerHook              \n",
            " -------------------- \n",
            "before_val_iter:\n",
            "(LOW         ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_iter:\n",
            "(LOW         ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_epoch:\n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            "(VERY_LOW    ) TensorboardLoggerHook              \n",
            " -------------------- \n",
            "after_run:\n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            "(VERY_LOW    ) TensorboardLoggerHook              \n",
            " -------------------- \n",
            "2023-02-21 17:28:32,002 - mmdet - INFO - workflow: [('train', 1)], max: 12 epochs\n",
            "2023-02-21 17:28:32,007 - mmdet - INFO - Checkpoints will be saved to /content/drive/MyDrive/Tomato-Dataset/mmdetection/results by HardDiskBackend.\n",
            "2023-02-21 17:38:34,653 - mmdet - INFO - Epoch [1][10/155]\tlr: 2.500e-03, eta: 1 day, 6:50:01, time: 60.001, data_time: 0.486, loss_rpn_cls: 0.0078, loss_rpn_bbox: 0.0176, loss_cls: 0.1975, acc: 92.0605, loss_bbox: 0.2309, loss_mask: 0.1628, loss: 0.6166\n",
            "2023-02-21 17:49:26,381 - mmdet - INFO - Epoch [1][20/155]\tlr: 2.500e-03, eta: 1 day, 7:59:19, time: 65.173, data_time: 0.061, loss_rpn_cls: 0.0112, loss_rpn_bbox: 0.0233, loss_cls: 0.2249, acc: 91.3965, loss_bbox: 0.2731, loss_mask: 0.1668, loss: 0.6992\n",
            "2023-02-21 18:00:38,216 - mmdet - INFO - Epoch [1][30/155]\tlr: 2.500e-03, eta: 1 day, 8:35:37, time: 67.183, data_time: 0.074, loss_rpn_cls: 0.0277, loss_rpn_bbox: 0.0211, loss_cls: 0.2040, acc: 92.4512, loss_bbox: 0.2152, loss_mask: 0.1345, loss: 0.6025\n",
            "2023-02-21 18:11:54,459 - mmdet - INFO - Epoch [1][40/155]\tlr: 2.500e-03, eta: 1 day, 8:51:31, time: 67.624, data_time: 0.055, loss_rpn_cls: 0.0097, loss_rpn_bbox: 0.0146, loss_cls: 0.1658, acc: 93.4473, loss_bbox: 0.2136, loss_mask: 0.1508, loss: 0.5545\n",
            "2023-02-21 18:23:00,948 - mmdet - INFO - Epoch [1][50/155]\tlr: 2.500e-03, eta: 1 day, 8:50:40, time: 66.649, data_time: 0.062, loss_rpn_cls: 0.0118, loss_rpn_bbox: 0.0184, loss_cls: 0.1860, acc: 93.2227, loss_bbox: 0.2141, loss_mask: 0.1483, loss: 0.5786\n",
            "2023-02-21 18:33:39,169 - mmdet - INFO - Epoch [1][60/155]\tlr: 2.500e-03, eta: 1 day, 8:32:15, time: 63.822, data_time: 0.065, loss_rpn_cls: 0.0110, loss_rpn_bbox: 0.0168, loss_cls: 0.1706, acc: 93.6133, loss_bbox: 0.2076, loss_mask: 0.1347, loss: 0.5407\n",
            "2023-02-21 18:45:08,561 - mmdet - INFO - Epoch [1][70/155]\tlr: 2.500e-03, eta: 1 day, 8:37:52, time: 68.939, data_time: 0.082, loss_rpn_cls: 0.0058, loss_rpn_bbox: 0.0168, loss_cls: 0.1981, acc: 91.7480, loss_bbox: 0.2063, loss_mask: 0.1400, loss: 0.5670\n",
            "2023-02-21 18:57:22,498 - mmdet - INFO - Epoch [1][80/155]\tlr: 2.500e-03, eta: 1 day, 8:55:44, time: 73.394, data_time: 0.103, loss_rpn_cls: 0.0127, loss_rpn_bbox: 0.0267, loss_cls: 0.1785, acc: 93.0371, loss_bbox: 0.2379, loss_mask: 0.1429, loss: 0.5987\n",
            "2023-02-21 19:08:53,754 - mmdet - INFO - Epoch [1][90/155]\tlr: 2.500e-03, eta: 1 day, 8:52:55, time: 69.126, data_time: 0.068, loss_rpn_cls: 0.0086, loss_rpn_bbox: 0.0201, loss_cls: 0.1412, acc: 94.4824, loss_bbox: 0.2079, loss_mask: 0.1330, loss: 0.5108\n",
            "2023-02-21 19:20:36,555 - mmdet - INFO - Epoch [1][100/155]\tlr: 2.500e-03, eta: 1 day, 8:51:45, time: 70.280, data_time: 0.071, loss_rpn_cls: 0.0055, loss_rpn_bbox: 0.0183, loss_cls: 0.1508, acc: 94.2969, loss_bbox: 0.2114, loss_mask: 0.1328, loss: 0.5188\n",
            "2023-02-21 19:31:22,373 - mmdet - INFO - Epoch [1][110/155]\tlr: 2.500e-03, eta: 1 day, 8:33:33, time: 64.582, data_time: 0.071, loss_rpn_cls: 0.0098, loss_rpn_bbox: 0.0205, loss_cls: 0.2074, acc: 91.4062, loss_bbox: 0.2305, loss_mask: 0.1587, loss: 0.6269\n",
            "2023-02-21 19:41:35,887 - mmdet - INFO - Epoch [1][120/155]\tlr: 2.500e-03, eta: 1 day, 8:08:47, time: 61.351, data_time: 0.047, loss_rpn_cls: 0.0085, loss_rpn_bbox: 0.0129, loss_cls: 0.1552, acc: 94.0039, loss_bbox: 0.1798, loss_mask: 0.1329, loss: 0.4893\n",
            "2023-02-21 19:51:57,774 - mmdet - INFO - Epoch [1][130/155]\tlr: 2.500e-03, eta: 1 day, 7:48:07, time: 62.189, data_time: 0.041, loss_rpn_cls: 0.0150, loss_rpn_bbox: 0.0156, loss_cls: 0.1377, acc: 95.1270, loss_bbox: 0.1652, loss_mask: 0.1176, loss: 0.4512\n",
            "2023-02-21 20:02:21,155 - mmdet - INFO - Epoch [1][140/155]\tlr: 2.500e-03, eta: 1 day, 7:29:14, time: 62.338, data_time: 0.041, loss_rpn_cls: 0.0079, loss_rpn_bbox: 0.0114, loss_cls: 0.1537, acc: 94.3262, loss_bbox: 0.1793, loss_mask: 0.1285, loss: 0.4808\n",
            "2023-02-21 20:12:12,001 - mmdet - INFO - Epoch [1][150/155]\tlr: 2.500e-03, eta: 1 day, 7:05:17, time: 59.085, data_time: 0.044, loss_rpn_cls: 0.0049, loss_rpn_bbox: 0.0156, loss_cls: 0.1330, acc: 94.9707, loss_bbox: 0.1901, loss_mask: 0.1287, loss: 0.4722\n",
            "2023-02-21 20:17:20,456 - mmdet - INFO - Saving checkpoint at 1 epochs\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 67/67, 0.1 task/s, elapsed: 572s, ETA:     0s"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-02-21 20:26:55,510 - mmdet - INFO - Evaluating bbox...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.45s).\n",
            "Accumulating evaluation results...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-02-21 20:26:56,220 - mmdet - INFO - \n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.594\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.839\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.658\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.402\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.569\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.700\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.736\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.736\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.736\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.558\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.698\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.840\n",
            "\n",
            "2023-02-21 20:26:56,221 - mmdet - INFO - Evaluating segm...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DONE (t=0.24s).\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Tomato-Dataset/mmdetection/mmdet/datasets/coco.py:470: UserWarning: The key \"bbox\" is deleted for more accurate mask AP of small/medium/large instances since v2.12.0. This does not change the overall mAP calculation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-02-21 20:26:56,888 - mmdet - INFO - \n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.630\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.834\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.697\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.392\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.589\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.783\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.772\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.772\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.772\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.609\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.723\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.888\n",
            "\n",
            "2023-02-21 20:26:56,899 - mmdet - INFO - Epoch(val) [1][67]\tbbox_mAP: 0.5938, bbox_mAP_50: 0.8390, bbox_mAP_75: 0.6577, bbox_mAP_s: 0.4019, bbox_mAP_m: 0.5685, bbox_mAP_l: 0.7004, bbox_mAP_copypaste: 0.5938 0.8390 0.6577 0.4019 0.5685 0.7004, segm_mAP: 0.6304, segm_mAP_50: 0.8338, segm_mAP_75: 0.6967, segm_mAP_s: 0.3915, segm_mAP_m: 0.5888, segm_mAP_l: 0.7835, segm_mAP_copypaste: 0.6304 0.8338 0.6967 0.3915 0.5888 0.7835\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DONE (t=0.27s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.07s).\n"
          ]
        }
      ],
      "source": [
        "# Build dataset\n",
        "datasets = [build_dataset(cfg.data.train)]\n",
        "\n",
        "# Build the detector\n",
        "model = build_detector(cfg.model)\n",
        "\n",
        "# Add an attribute for visualization convenience\n",
        "model.CLASSES = datasets[0].CLASSES\n",
        "\n",
        "# Create work_dir\n",
        "mmcv.mkdir_or_exist(os.path.abspath(cfg.work_dir))\n",
        "train_detector(model, datasets, cfg, distributed=False, validate=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8I7BgZMEquR",
        "outputId": "dcc6df52-8e34-4c5c-cb23-336224d7cba0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Tomato-Dataset/mmdetection\n",
            "No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n",
            "/usr/local/lib/python3.8/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
            "  warnings.warn(\n",
            "tools/test.py:116: UserWarning: --options is deprecated in favor of --eval-options\n",
            "  warnings.warn('--options is deprecated in favor of --eval-options')\n",
            "/content/drive/MyDrive/Tomato-Dataset/mmdetection/mmdet/utils/setup_env.py:38: UserWarning: Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\n",
            "  warnings.warn(\n",
            "/content/drive/MyDrive/Tomato-Dataset/mmdetection/mmdet/utils/setup_env.py:48: UserWarning: Setting MKL_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\n",
            "  warnings.warn(\n",
            "loading annotations into memory...\n",
            "Done (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "load checkpoint from local path: /content/drive/MyDrive/Tomato-Dataset/mmdetection/results/Results1/epoch_1.pth\n",
            "[>>] 66/66, 0.1 task/s, elapsed: 577s, ETA:     0s"
          ]
        }
      ],
      "source": [
        "# PREDICT\n",
        "%cd /content/drive/MyDrive/Tomato-Dataset/mmdetection\n",
        "\n",
        "!python tools/test.py\\\n",
        "configs/mask_rcnn/tomato_custom_mask_rcnn.py\\\n",
        "/content/drive/MyDrive/Tomato-Dataset/mmdetection/results/Results3/epoch_1.pth\\\n",
        "--show-score-thr 0.5\\\n",
        "--show-dir /content/drive/MyDrive/Tomato-Dataset/mmdetection/results/Results3/eval\\\n",
        "--format-only\\\n",
        "--options 'jsonfile_prefix=/content/drive/MyDrive/Tomato-Dataset/mmdetection/results/Results1/test-dev_results'\\"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.13 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "f31275358cf534c5bfced08dac3381a2a54ac80ee284b073ad34f287f0626321"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
